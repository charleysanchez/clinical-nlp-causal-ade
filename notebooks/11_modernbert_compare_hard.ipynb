{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90382b05",
   "metadata": {},
   "source": [
    "# BioClinical ModernBERT vs ModernBERT — Causal ADE Classification (Synthetic Notes)\n",
    "\n",
    "This notebook benchmarks **BioClinical ModernBERT** against **vanilla ModernBERT**\n",
    "for detecting **causal Adverse Drug Events (ADEs)** in synthetic ICU notes.\n",
    "\n",
    "We use a synthetic dataset (`notes_hard_v4.csv`, `doc_labels_hard_v4`) that contains both **textual** and **structural** signals \n",
    "for drug–ADE relationships. Each note is labeled positive only when both:\n",
    "\n",
    "- The patient was *treated with an ACE inhibitor* (`T=1`), **and**\n",
    "- The note explicitly links the treatment to an **adverse outcome** (`AKI=1` with causal phrasing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08a4b5",
   "metadata": {},
   "source": [
    "## 1. Load the Synthetic Dataset\n",
    "\n",
    "We load `notes_hard.csv` and `doc_labels_hard.csv`, then merge them on `doc_id`.  \n",
    "Each note contains free text describing an ICU admission, while `hard_label` encodes the binary ADE outcome.\n",
    "\n",
    "The dataset has:\n",
    "- Text field (`text`)\n",
    "- Label field (`hard_label`)\n",
    "- Roughly balanced class distribution\n",
    "\n",
    "Let's preview and confirm the merge worked correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512309a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6464, 1536)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, random\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_DIR = os.environ.get(\"DATA_DIR\", \"../data/synth_clinical\")\n",
    "\n",
    "notes_v4  = os.path.join(DATA_DIR, \"notes_hard_v4.csv\")\n",
    "labels_v4 = os.path.join(DATA_DIR, \"doc_labels_hard_v4.csv\")\n",
    "\n",
    "notes = pd.read_csv(notes_v4)\n",
    "labs  = pd.read_csv(labels_v4)\n",
    "df = notes.merge(labs[['doc_id','label','split']], on='doc_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff9ab4e",
   "metadata": {},
   "source": [
    "## 2. Prepare the Dataset for Modeling\n",
    "\n",
    "We convert the merged dataframe into a Hugging Face `Dataset` and split 80/20 into \n",
    "training and test subsets.\n",
    "\n",
    "This allows us to evaluate generalization on unseen synthetic notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd09b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient admitted to ICU with SOFA score of 3. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patient admitted to ICU with SOFA score of 9. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ADE] noted duing treatment with [DRUG]. Patie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Care plan discussed with team. Patient admitte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patient admitted to ICU with SOFA score of 4. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>Care plan discussed with team. Patient admitte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>Soon after {drug} was begun, creatinine remain...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6461</th>\n",
       "      <td>Patient admitted to ICU with SOFA score of 4. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6462</th>\n",
       "      <td>Patinet admitted to ICU with SOFA score of 7. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>[ADE] noted during treatment with ACE inhibito...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Patient admitted to ICU with SOFA score of 3. ...      0\n",
       "1     Patient admitted to ICU with SOFA score of 9. ...      1\n",
       "2     [ADE] noted duing treatment with [DRUG]. Patie...      1\n",
       "3     Care plan discussed with team. Patient admitte...      0\n",
       "4     Patient admitted to ICU with SOFA score of 4. ...      0\n",
       "...                                                 ...    ...\n",
       "6459  Care plan discussed with team. Patient admitte...      1\n",
       "6460  Soon after {drug} was begun, creatinine remain...      0\n",
       "6461  Patient admitted to ICU with SOFA score of 4. ...      0\n",
       "6462  Patinet admitted to ICU with SOFA score of 7. ...      0\n",
       "6463  [ADE] noted during treatment with ACE inhibito...      0\n",
       "\n",
       "[6464 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['split']=='train'][['text','label']].reset_index(drop=True)\n",
    "test_df  = df[df['split']=='test'][['text','label']].reset_index(drop=True)\n",
    "\n",
    "ds = {\n",
    "    \"train\": Dataset.from_pandas(train_df),\n",
    "    \"test\":  Dataset.from_pandas(test_df),\n",
    "}\n",
    "len(ds[\"train\"]), len(ds[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce30f32e",
   "metadata": {},
   "source": [
    "## 3. Define Evaluation Metrics\n",
    "\n",
    "For consistency with biomedical NLP literature, we evaluate:\n",
    "\n",
    "- **Accuracy** — overall classification correctness  \n",
    "- **F1 Score** — harmonic mean of precision & recall  \n",
    "- **AUROC** — area under the ROC curve (ranking ability)  \n",
    "- **AUPRC** — area under the precision–recall curve (robust to imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16a85024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = logits - logits.max(axis=1, keepdims=True)\n",
    "    probs = np.exp(probs)\n",
    "    probs = probs[:,1] / probs.sum(axis=1)\n",
    "    preds=(probs>=0.5).astype(int)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds),\n",
    "        'auroc': roc_auc_score(labels, probs),\n",
    "        'auprc': average_precision_score(labels, probs)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4db10",
   "metadata": {},
   "source": [
    "## 4. Define Model Training Routine\n",
    "\n",
    "We create a helper `run_model()` that:\n",
    "\n",
    "1. Loads the chosen pretrained ModernBERT tokenizer & model  \n",
    "2. Tokenizes text up to a maximum sequence length  \n",
    "3. Trains for a configurable number of epochs  \n",
    "4. Logs key metrics on the validation set after each epoch\n",
    "\n",
    "The function returns a dictionary of performance statistics for easy comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec11d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_name:str, max_len=768, epochs=3, batch=16, lr=2e-5, fp16=True):\n",
    "    tok=AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "\n",
    "    def tokenize(batch):\n",
    "        return tok(batch[\"text\"], max_length=max_len, truncation=True)\n",
    "    \n",
    "    \n",
    "    # If ds is a dict of splits, tokenize per split\n",
    "    if isinstance(ds, dict):\n",
    "        enc = {split: d.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "               for split, d in ds.items()}\n",
    "        train_ds = enc[\"train\"]\n",
    "        eval_ds  = enc.get(\"test\") or enc.get(\"validation\")\n",
    "        if eval_ds is None:\n",
    "            raise ValueError(\"No eval split found in ds; expected 'test' or 'validation'.\")\n",
    "    else:\n",
    "        # ds is a DatasetDict (or similar) with map and split keys\n",
    "        enc = ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "        train_ds = enc[\"train\"]\n",
    "        eval_ds  = enc.get(\"test\") or enc.get(\"validation\")    \n",
    "    \n",
    "    model=AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    args=TrainingArguments(\n",
    "        output_dir=f\"../reports/doc_cls_hard_{model_name.replace('/','_')}\",\n",
    "        per_device_train_batch_size=batch,\n",
    "        per_device_eval_batch_size=batch,\n",
    "        num_train_epochs=epochs,\n",
    "        learning_rate=lr,\n",
    "        weight_decay=0.05,\n",
    "        lr_scheduler_type='cosine',\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=fp16,\n",
    "        logging_steps=50,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        label_smoothing_factor=0.05,\n",
    "        report_to=[],\n",
    "        seed=SEED\n",
    "    )\n",
    "    trainer=Trainer(model=model, args=args, train_dataset=enc['train'], eval_dataset=enc['test'], tokenizer=tok, compute_metrics=compute_metrics)\n",
    "    import time; t0=time.time(); trainer.train(); dur=time.time()-t0\n",
    "    metrics=trainer.evaluate(); metrics['seconds']=dur; return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162111a8",
   "metadata": {},
   "source": [
    "## 5. Train and Compare Models\n",
    "\n",
    "We benchmark two architectures:\n",
    "\n",
    "| Model | Description |\n",
    "|--------|--------------|\n",
    "| **BioClinical ModernBERT** | Domain-adapted version trained on biomedical corpora (MIMIC, PubMed) |\n",
    "| **ModernBERT (vanilla)** | General English version trained on large web text |\n",
    "\n",
    "Both are fine-tuned for binary sequence classification on our synthetic ADE dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "946d431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Training BioClinical ModernBERT: thomas-sounack/BioClinical-ModernBERT-base ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6464/6464 [00:00<00:00, 28757.36 examples/s]\n",
      "Map: 100%|██████████| 1536/1536 [00:00<00:00, 22951.05 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at thomas-sounack/BioClinical-ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_862/2523521955.py:40: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer=Trainer(model=model, args=args, train_dataset=enc['train'], eval_dataset=enc['test'], tokenizer=tok, compute_metrics=compute_metrics)\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='868' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 868/2020 01:51 < 02:28, 7.73 it/s, Epoch 4.29/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.315500</td>\n",
       "      <td>0.329600</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.946085</td>\n",
       "      <td>0.952462</td>\n",
       "      <td>0.940787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.267800</td>\n",
       "      <td>0.274074</td>\n",
       "      <td>0.953776</td>\n",
       "      <td>0.954863</td>\n",
       "      <td>0.952780</td>\n",
       "      <td>0.949004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.286600</td>\n",
       "      <td>0.260310</td>\n",
       "      <td>0.953776</td>\n",
       "      <td>0.954806</td>\n",
       "      <td>0.954908</td>\n",
       "      <td>0.948426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.262458</td>\n",
       "      <td>0.954427</td>\n",
       "      <td>0.955471</td>\n",
       "      <td>0.950197</td>\n",
       "      <td>0.943677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mn \u001b[38;5;129;01min\u001b[39;00m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBioClinical ModernBERT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthomas-sounack/BioClinical-ModernBERT-base\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      3\u001b[0m                  (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModernBERT (vanilla)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswerdotai/ModernBERT-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)]:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==== Training \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     results[name]\u001b[38;5;241m=\u001b[39m\u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m results\n",
      "Cell \u001b[0;32mIn[33], line 41\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(model_name, max_len, epochs, batch, lr, fp16)\u001b[0m\n\u001b[1;32m     23\u001b[0m args\u001b[38;5;241m=\u001b[39mTrainingArguments(\n\u001b[1;32m     24\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../reports/doc_cls_hard_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     seed\u001b[38;5;241m=\u001b[39mSEED\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m trainer\u001b[38;5;241m=\u001b[39mTrainer(model\u001b[38;5;241m=\u001b[39mmodel, args\u001b[38;5;241m=\u001b[39margs, train_dataset\u001b[38;5;241m=\u001b[39menc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], eval_dataset\u001b[38;5;241m=\u001b[39menc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m], tokenizer\u001b[38;5;241m=\u001b[39mtok, compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m; t0\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime(); \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m; dur\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mt0\n\u001b[1;32m     42\u001b[0m metrics\u001b[38;5;241m=\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mevaluate(); metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseconds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdur; \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/programming/clinical-nlp-causal-ade/venv/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programming/clinical-nlp-causal-ade/venv/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/programming/clinical-nlp-causal-ade/venv/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/programming/clinical-nlp-causal-ade/venv/lib/python3.10/site-packages/accelerate/accelerator.py:2736\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2735\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2736\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[0;32m~/programming/clinical-nlp-causal-ade/venv/lib/python3.10/site-packages/torch/_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[0;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programming/clinical-nlp-causal-ade/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programming/clinical-nlp-causal-ade/venv/lib/python3.10/site-packages/torch/autograd/graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results={}\n",
    "for name, mn in [(\"BioClinical ModernBERT\", \"thomas-sounack/BioClinical-ModernBERT-base\"),\n",
    "                 (\"ModernBERT (vanilla)\", \"answerdotai/ModernBERT-base\")]:\n",
    "    print(f\"\\n==== Training {name}: {mn} ====\")\n",
    "    results[name]=run_model(mn, max_len=512, epochs=10, batch=32, lr=1e-5)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7b65c2",
   "metadata": {},
   "source": [
    "## 6. Results Summary\n",
    "\n",
    "Below we summarize final evaluation metrics after fine-tuning.\n",
    "\n",
    "Values close to **1.0** indicate that the task is relatively easy for these models — likely because \n",
    "the dataset contains strong lexical cues (\"after starting\", \"denies\", \"no evidence of\", etc.) \n",
    "that the models can exploit directly.\n",
    "\n",
    "Subsequent versions of the dataset (`hard_v2`, `hard_v3`, `hard_v4`) progressively remove such shortcuts \n",
    "to test deeper reasoning and contextual understanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dbd453a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_auroc</th>\n",
       "      <th>eval_auprc</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BioClinical ModernBERT</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>30.437208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ModernBERT (vanilla)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>29.712710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        eval_accuracy  eval_f1  eval_auroc  eval_auprc  \\\n",
       "BioClinical ModernBERT            1.0      1.0         1.0         1.0   \n",
       "ModernBERT (vanilla)              1.0      1.0         1.0         1.0   \n",
       "\n",
       "                        eval_loss    seconds  \n",
       "BioClinical ModernBERT   0.000944  30.437208  \n",
       "ModernBERT (vanilla)     0.000246  29.712710  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).T[['eval_accuracy','eval_f1','eval_auroc','eval_auprc','eval_loss','seconds']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f99e9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split  label\n",
      "test   0        0.8250\n",
      "       1        0.1750\n",
      "train  0        0.8375\n",
      "       1        0.1625\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('split')['label'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf300d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes = pd.read_csv(f\"{DATA_DIR}/notes_hard_v4.csv\")\n",
    "# labs  = pd.read_csv(f\"{DATA_DIR}/doc_labels_hard_v4.csv\")\n",
    "# df = notes.merge(labs[['doc_id','split','label']], on='doc_id')\n",
    "\n",
    "CUES  = [\"after starting\", \"following initiation\", \"soon after\",\n",
    "         \"temporal association\", \"shortly post-initiation\", \"in close proximity\"]\n",
    "NEGS  = [\"no evidence of\", \"denies\", \"without signs of\", \"not \", \"unlikely to\"]\n",
    "\n",
    "def keyword_baseline(text):\n",
    "    t = text.lower()\n",
    "    cue = any(c in t for c in CUES)\n",
    "    neg = any(n in t for n in NEGS)\n",
    "    return int(cue and not neg)   # 1 = positive guess, else 0\n",
    "\n",
    "for split in [\"train\",\"test\"]:\n",
    "    p = df[df.split==split]\n",
    "    preds = p.text.map(keyword_baseline).values\n",
    "    acc = (preds == p.label.values).mean()\n",
    "    print(f\"{split} keyword baseline accuracy: {acc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
