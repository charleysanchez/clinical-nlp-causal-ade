{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2512309a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 120)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, random\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_DIR = os.environ.get(\"DATA_DIR\", \"../data/synth_clinical\")\n",
    "\n",
    "notes_v2  = os.path.join(DATA_DIR, \"notes_hard_v2.csv\")\n",
    "labels_v2 = os.path.join(DATA_DIR, \"doc_labels_hard_v2.csv\")\n",
    "\n",
    "notes = pd.read_csv(notes_v2)\n",
    "labs  = pd.read_csv(labels_v2)\n",
    "df = notes.merge(labs[['doc_id','hard_v2_label','split']], on='doc_id', how='left').rename(columns={'hard_v2_label':'label'})\n",
    "\n",
    "train_df = df[df['split']=='train'][['text','label']].reset_index(drop=True)\n",
    "test_df  = df[df['split']=='test'][['text','label']].reset_index(drop=True)\n",
    "\n",
    "ds = {\n",
    "    \"train\": Dataset.from_pandas(train_df),\n",
    "    \"test\":  Dataset.from_pandas(test_df),\n",
    "}\n",
    "len(ds[\"train\"]), len(ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16a85024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = logits - logits.max(axis=1, keepdims=True)\n",
    "    probs = np.exp(probs)\n",
    "    probs = probs[:,1] / probs.sum(axis=1)\n",
    "    preds=(probs>=0.5).astype(int)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds),\n",
    "        'auroc': roc_auc_score(labels, probs),\n",
    "        'auprc': average_precision_score(labels, probs)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec11d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_name:str, max_len=768, epochs=3, batch=16, lr=2e-5, fp16=True):\n",
    "    tok=AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "    enc=ds['train'].map(lambda x: tok(x['text'], max_length=max_len, truncation=True), batched=True, remove_columns=['text'])\n",
    "    model=AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    args=TrainingArguments(\n",
    "        output_dir=f\"../reports/doc_cls_hard_{model_name.replace('/','_')}\",\n",
    "        per_device_train_batch_size=batch,\n",
    "        per_device_eval_batch_size=batch,\n",
    "        num_train_epochs=epochs,\n",
    "        learning_rate=lr,\n",
    "        fp16=fp16,\n",
    "        logging_steps=50,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        report_to=[],\n",
    "        seed=SEED\n",
    "    )\n",
    "    trainer=Trainer(model=model, args=args, train_dataset=enc['train'], eval_dataset=enc['test'], tokenizer=tok, compute_metrics=compute_metrics)\n",
    "    import time; t0=time.time(); trainer.train(); dur=time.time()-t0\n",
    "    metrics=trainer.evaluate(); metrics['seconds']=dur; return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Training BioClinical ModernBERT: thomas-sounack/BioClinical-ModernBERT-base ====\n"
     ]
    }
   ],
   "source": [
    "results={}\n",
    "for name, mn in [(\"BioClinical ModernBERT\", \"thomas-sounack/BioClinical-ModernBERT-base\"),\n",
    "                 (\"ModernBERT (vanilla)\", \"answerdotai/ModernBERT-base\")]:\n",
    "    print(f\"\\n==== Training {name}: {mn} ====\")\n",
    "    results[name]=run_model(mn, max_len=1024, epochs=10)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).T[['accuracy','f1','auroc','auprc','eval_loss','seconds']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
